{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a6ab9a2-28a2-445d-8512-a0dc8d1b54e9",
   "metadata": {},
   "source": [
    "# Code Generator\n",
    "\n",
    "The requirement: use a Frontier model to generate high performance C++ code from Python code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90e04a2-5b8a-4fd5-9db8-27c02f033313",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td>\n",
    "            <h1 style=\"color:#900;\">Important Note</h1>\n",
    "            <span style=\"color:#900;\">\n",
    "            In this lab, I use GPT-4o which is the slightly higher priced model. The costs are still low, but if you'd prefer to keep costs ultra low, please make the suggested switches to the models (3 cells down from here).\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e610bf56-a46e-4aff-8de1-ab49d62b1ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import google.generativeai\n",
    "import anthropic\n",
    "from IPython.display import Markdown, display, update_display\n",
    "import gradio as gr\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f672e1c-87e9-4865-b760-370fa605e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aa149ed-9298-4d69-8fe2-8f5de0f667da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "# NOTE - option to use ultra-low cost models by uncommenting last line\n",
    "\n",
    "openai = OpenAI()\n",
    "OPENAI_MODEL = \"gpt-4o\"\n",
    "\n",
    "# OPENAI_MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6896636f-923e-4a2c-9d6c-fac07828a201",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an assistant that reimplements Python code in high performance C++ for an M3 Mac. \"\n",
    "system_message += \"Respond only with C++ code; use comments sparingly and do not provide any explanation other than occasional comments. \"\n",
    "system_message += \"The C++ response needs to produce an identical output in the fastest possible time.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e7b3546-57aa-4c29-bc5d-f211970d04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_prompt_for(python):\n",
    "    user_prompt = \"Rewrite this Python code in C++ with the fastest possible implementation that produces identical output in the least time. \"\n",
    "    user_prompt += \"Respond only with C++ code; do not explain your work other than a few comments. \"\n",
    "    user_prompt += \"Pay attention to number types to ensure no int overflows. Remember to #include all necessary C++ packages such as iomanip.\\n\\n\"\n",
    "    user_prompt += python\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6190659-f54c-4951-bef4-4960f8e51cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(python):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(python)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71e1ba8c-5b05-4726-a9f3-8d8c6257350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to a file called optimized.cpp\n",
    "\n",
    "def write_output(cpp):\n",
    "    code = cpp.replace(\"```cpp\",\"\").replace(\"```\",\"\")\n",
    "    with open(\"optimized.cpp\", \"w\") as f:\n",
    "        f.write(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7d2fea8-74c6-4421-8f1e-0e76d5b201b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_gpt(python):    \n",
    "    stream = openai.chat.completions.create(model=OPENAI_MODEL, messages=messages_for(python), stream=True)\n",
    "    reply = \"\"\n",
    "    for chunk in stream:\n",
    "        fragment = chunk.choices[0].delta.content or \"\"\n",
    "        reply += fragment\n",
    "        print(fragment, end='', flush=True)\n",
    "    write_output(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1cbb778-fa57-43de-b04b-ed523f396c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = \"\"\"\n",
    "import time\n",
    "\n",
    "def calculate(iterations, param1, param2):\n",
    "    result = 1.0\n",
    "    for i in range(1, iterations+1):\n",
    "        j = i * param1 - param2\n",
    "        result -= (1/j)\n",
    "        j = i * param1 + param2\n",
    "        result += (1/j)\n",
    "    return result\n",
    "\n",
    "start_time = time.time()\n",
    "result = calculate(100_000_000, 4, 1) * 4\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Result: {result:.12f}\")\n",
    "print(f\"Execution Time: {(end_time - start_time):.6f} seconds\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fe1cd4b-d2c5-4303-afed-2115a3fef200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 3.141592658589\n",
      "Execution Time: 6.798859 seconds\n"
     ]
    }
   ],
   "source": [
    "exec(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "105db6f9-343c-491d-8e44-3a5328b81719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```cpp\n",
      "#include <iostream>\n",
      "#include <iomanip>\n",
      "#include <chrono>\n",
      "\n",
      "double calculate(int iterations, int param1, int param2) {\n",
      "    double result = 1.0;\n",
      "    for (int i = 1; i <= iterations; ++i) {\n",
      "        double j = i * param1 - param2;\n",
      "        result -= (1.0 / j);\n",
      "        j = i * param1 + param2;\n",
      "        result += (1.0 / j);\n",
      "    }\n",
      "    return result;\n",
      "}\n",
      "\n",
      "int main() {\n",
      "    auto start_time = std::chrono::high_resolution_clock::now();\n",
      "    \n",
      "    double result = calculate(100000000, 4, 1) * 4;\n",
      "    \n",
      "    auto end_time = std::chrono::high_resolution_clock::now();\n",
      "    std::chrono::duration<double> execution_time = end_time - start_time;\n",
      "    \n",
      "    std::cout << std::fixed << std::setprecision(12);\n",
      "    std::cout << \"Result: \" << result << std::endl;\n",
      "    std::cout << \"Execution Time: \" << execution_time.count() << \" seconds\" << std::endl;\n",
      "    \n",
      "    return 0;\n",
      "}\n",
      "```"
     ]
    }
   ],
   "source": [
    "optimize_gpt(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8f8018-f64d-425c-a0e1-d7862aa9592d",
   "metadata": {},
   "source": [
    "# Compiling C++ and executing\n",
    "\n",
    "This next cell contains the command to compile a C++ file on my M3 Mac.  \n",
    "It compiles the file `optimized.cpp` into an executable called `optimized`  \n",
    "Then it runs the program called `optimized`\n",
    "\n",
    "You can google (or ask ChatGPT!) for how to do this on your platform, then replace the lines below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4194e40c-04ab-4940-9d64-b4ad37c5bb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 3.141592658589\n",
      "Execution Time: 0.139479209000 seconds\n"
     ]
    }
   ],
   "source": [
    "# Compile C++ and run the executable\n",
    "\n",
    "!clang++ -O3 -std=c++17 -march=armv8.3-a -o optimized optimized.cpp\n",
    "!./optimized"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
